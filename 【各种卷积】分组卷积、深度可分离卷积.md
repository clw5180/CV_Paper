# **Group Convolution分组卷积，以及Depthwise Convolution和Global Depthwise Convolution**

参考：https://www.cnblogs.com/shine-lee/p/10243114.html



## 一、写在前面

**Group Convolution分组卷积**，最早见于AlexNet——2012年Imagenet的冠军方法，Group Convolution被用来切分网络，使其在2个GPU上并行运行，AlexNet网络结构如下：



![这里随便写文字](https://github.com/clw5180/CV_Paper/blob/master/res/分组卷积/1.png)





## 二、主要内容

#### Convolution VS Group Convolution

在介绍**Group Convolution**前，先回顾下**常规卷积**是怎么做的，具体可以参见博文[《卷积神经网络之卷积计算、作用与思想》](https://blog.shinelee.me/2018/11-08-卷积神经网络之卷积计算、作用与思想.html)。如果输入feature map尺寸为 𝐶 x 𝐻 x 𝑊，卷积核有*𝑁*个，输出feature map与卷积核的数量相同也是*𝑁*，每个卷积核的尺寸为 𝐶 x 𝐾 x 𝐾，𝑁个卷积核的总参数量为 𝑁 x 𝐶 x 𝐾 x 𝐾 ，输入map与输出map的连接方式如下图左所示，图片来自[链接](https://www.researchgate.net/figure/The-transformations-within-a-layer-in-DenseNets-left-and-CondenseNets-at-training-time_fig2_321325862)：

![这里随便写文字](https://github.com/clw5180/CV_Paper/blob/master/res/分组卷积/2.png)

**Group Convolution**顾名思义，则是对输入feature map进行分组，然后每组分别卷积。假设输入feature map的尺寸仍为*𝐶* x*𝐻 x*𝑊，输出feature map的数量为 𝑁 个，如果设定要分成𝐺 *个groups，则每组的输入feature map数量为*𝐶/𝐺，每组的输出feature map数量为*𝑁* /*𝐺*，每个卷积核的尺寸为*𝐶/𝐺* x 𝐾 x 𝐾，卷积核的总数仍为 𝑁 个，每组的卷积核数量为 𝑁 /𝐺，卷积核只与其同组的输入map进行卷积，卷积核的总参数量为 𝑁 x 𝐶/𝐺 x 𝐾 x 𝐾，可见，**总参数量减少为原来的 1/𝐺**，其连接方式如上图右所示，group1输出map数为2，有2个卷积核，每个卷积核的channel数为4，与group1的输入map的channel数相同，卷积核只与同组的输入map卷积，而不与其他组的输入map卷积。



#### Group Convolution的用途

- **减少参数量**，分成1/*𝐺*

- **Group Convolution可以看成是structured sparse**，每个卷积核的尺寸由 𝐶 x 𝐾 x 𝐾变为(𝐶 − 𝐶/𝐺) x 𝐾 x 𝐾，可以将其余(𝐶− 𝐶/𝐺) x 𝐾 x 𝐾的参数视为0，有时甚至可以在减少参数量的同时获得更好的效果（相当于**正则**）。

- 当分组数量等于输入map数量，输出map数量也等于输入map数量，即 𝐺 = 𝑁 = 𝐶、𝑁个卷积核每个尺寸为1 x 𝐾 x 𝐾 时，Group Convolution就成了**Depthwise Convolution**，参见[MobileNet](https://arxiv.org/abs/1704.04861)和[Xception](https://arxiv.org/abs/1610.02357)等，**参数量进一步缩减**，如下图所示

![这里随便写文字](https://github.com/clw5180/CV_Paper/blob/master/res/分组卷积/3.png)

- 更进一步，如果分组数 𝐺 = 𝑁 = 𝐶，同时卷积核的尺寸与输入map的尺寸相同，即 𝐾 = 𝐻 = 𝑊 ，则输出map为 𝐶 x 1 x 1即长度为 𝐶 的向量，此时称之为**Global Depthwise Convolution（GDC）**，见[MobileFaceNet](https://arxiv.org/abs/1804.07573)，可以看成是**全局加权池化**，与 **Global Average Pooling（GAP）** 的不同之处在于，GDC **给每个位置赋予了可学习的权重**（对于已对齐的图像这很有效，比如人脸，中心位置和边界位置的权重自然应该不同），而GAP每个位置的权重相同，全局取个平均，如下图所示：

![这里随便写文字](https://github.com/clw5180/CV_Paper/blob/master/res/分组卷积/4.png)