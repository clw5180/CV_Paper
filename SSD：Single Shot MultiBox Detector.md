# **SSD: Single Shot MultiBox Detector**

论文地址：<https://arxiv.org/abs/1512.02325>

代码复现：https://github.com/weiliu89/caffe/tree/ssd （作者实现）



## 一、介绍

&emsp;&emsp;SSD是单阶段检测器。对于300x300的输入图片，可以在VOC2007上达到74.3%的mAP，并且速度高达59FPS；对于512x512更大尺寸的输入，SSD可以达到更高的76.9%的mAP，甚至超过了Faster R-CNN；在经过**改进的数据增强方法**后，可以分别达到77.2%和79.8%的mAP，可以看到**提高了3个点左右**。相对于其他单阶段监测器，SSD可以在较小的输入尺寸上得到较大的精确度。在速度上的提高主要是通过去掉了bbox的候选框，以及去掉了特征重采样的部分；

![这里随便写文字](https://github.com/clw5180/CV_Paper/raw/master/res/SSD/1.png)

&emsp;&emsp;SSD使用了多尺度feature map，如上图，狗比猫的尺度更大，在8x8的特征图中不能检测出大狗，但能检测出猫，而在4x4的特征图中就可以检测出狗，却不能检测出猫。这样，不同尺度的目标就可以通过不同层的特征图检测出。



## 二、主要内容
SSD 将输出一系列 离散化（discretization） 的 bounding boxes，这些 bounding boxes 是在不同层次（layers） 上的 feature maps 上生成的，并且有着不同的aspect ratio。

![这里随便写文字](https://github.com/clw5180/CV_Paper/raw/master/res/SSD/2.png)

**SSD对小目标检测效果不好，因为conv4_3的feature map不够大**。小物体在较高层的特征图上只能保留很少的信息。这里只能通过**增加输入图像的尺寸**来解决对小物体检测效果。


anchor的直观理解：按照不同的 scale 和 ratio 生成，k 个 default boxes，这种结构有点类似于 Faster R-CNN 中的 Anchor。(此处k=6所以：5*5*6 = 150 boxes)
![这里随便写文字](https://pic4.zhimg.com/80/v2-e128c01e26456fa24502e2c05bf46e1b_hd.png)


从模型结构中, 我们可以看到, SSD实际是一个全卷积网络. 如下图左上角所示, 其最后的完整输出是一个长方体, 这个长方体长宽都为m, 通道数=k*(n_label+4), 其中n_label是预测的种类数, 4是坐标数, k是anchor种类数(anchor种类的大小与长宽比有关). 如下图右上角所示, 我们可以把一个完整的输出, 拆分成k*m*m个单独输出, 每个输出都包括类别(n_label)与4个bbox坐标, 即(n_label+4). 每一个这样的单独输出都与一个anchor对应, 即与输入的一个固定的矩形区域对应. 如图所示, 每一个输出, 都对应输入图像的一个anchor.
![这里随便写文字](https://pic4.zhimg.com/80/v2-d63f206123ab5b2120c1db30750444af_hd.jpg)


**对bbox的预测有以下注意点**: （以下参考https://zhuanlan.zhihu.com/p/29410169）
使用smoothL1, 而不使用L2loss, 是因为若采用L2loss, 在训练时, 某些预测结果与实际相差太大, L2loss的梯度将过大, 影响训练. 而smoothL1在偏差较大时, 不会有类似问题.
论文回归的目标对象是, 物体的bbox中心点坐标与anchor中心点坐标的偏移, 以及物体bbox的长宽与anchor的长宽的比值. 并不是对bbox四个点坐标做回归.
2.1.5. Data Augmentation
训练数据集进行如下数据增广:
1、完整的图
2、crop(由于SSD是在不同特征层会预测不同大小的物体, 为了保证每个特征层都得到充分训练(特别是最后几层), 进行了图像的Crop, 这样相当于放大了一个物体)
（1）对图像采样一个patch, 该patch的条件是与物体的IoU为0.1 0.3 0.5 0.7 0.9
（2）random crop，且保证物体中心点在crop区域
（3）crop后, ground truth将会被同样裁剪到crop图与ground truth重叠地区域
3、翻转
zoom out(将一张图缩小, 并进行padding后作为输入, 有利于预测小物体)

2.2 SSD在训练什么
要弄懂一个模型, 不能只知道模型的结构是什么样的, 还要理解模型在训练时, 到底是在训练什么, 这包括训练的输入, 输出. 但之前我们不是已经说过输入输出是什么了吗? 后面, 我们将拆解模型的输入输出, 理解SSD到底在训练什么.

2.2.1 输出与感受野

可以通过计算得知, 网络不同层级的输出对应输入的感受野并不是整张图, 可能比整张图小, 也可能比整张图大. 对于感受野比图小的例子, 可以见下图, 一般层级较浅的输出, 比如(38, 38), (19, 19)的输出感受野都要小于整张图. 因此他们并不是用整张图来训练.
![这里随便写文字](https://pic4.zhimg.com/80/v2-f82f08dfad40766418b3f027412b7db7_hd.jpg)
而感受野大于输入的情况一般发生在层级比较深的输出, 在感受野大于输入时, 可以理解为感受野大于的部分都是padding, 如下图:
![这里随便写文字](https://pic3.zhimg.com/80/v2-c2f9eddae255fc61594f4537bcb5744a_hd.jpg)

2.2.2 全卷积分解为多个单输出的卷积

SSD的输出是一系列的全卷积网络, 实际上由于卷积时权值共享的, 可以把全卷积当做对一张图的不同部分做单输出的卷积, 然后把卷积结果按顺序排列, 如下图:
![这里随便写文字](https://pic3.zhimg.com/80/v2-a523614f974f52e196bfecf90125d892_hd.jpg)

上图中, 原始图像经过全卷积得到蓝绿红黄四个输出, 其输出对应输入的感受野也由对应的颜色体现, 我们可以把感受野拆成对应的四幅图, 由于全卷积网络是权值共享的, 因此可以认为是每次四张子图都通过一个相同的cnn, 得到输出, 然后将输出按顺序拼接.
所以, SSD的训练可以近似为把一张图拆分成无数个不同大小的子图, 然后做单一输出的分类与定位. 事实上这与滑动窗口十分相似.
![这里随便写文字](https://pic2.zhimg.com/80/v2-d9511060c2cd20c45eed7963070f68ed_hd.jpg)

2.2.3 训练的目标

再回到anchor, 每个输出都有一个对应的感受野, 也有一个anchor, 虽然我们每次输入感受野内的图像, 但并不以感受野存在物体而就认为它的输出是这个物体. 只有当感受野内的anchor满足与物体iou大于0.5, 才预测存在物体. 因此, 总结起来, 我们学习的实际是一张图(感受野)与固定范围(anchor)的iou大于0.5的物体是什么, 以及这个物体相对于anchor位置的偏移量什么. 因此, anchor实际上就是一个RoI, 相比于fast-rcnn的roi, SSD的roi是固定的, 且每个roi都有输出.

总结起来, 不严格地讲, SSD训练一张图片, 如下图左边图所示, 相当于把一张完整图切分成大大小小8732张子图(300*300的模型一共有8732个anchor), 每张子图都有一个固定的RoI区域(如下图中间部分所示), 然后以8732张子图作为一个batch进行训练. 在训练时, 如果RoI区域与物体满足IoU条件, 我们将其对应的label设为该物体, 并且预测其与对应anchor的偏移, 否则预测为背景. 这样当预测时, 也是把一张图切成这么多子图, 然后分别进行预测.

SSD预测的目标就是以一张图中所有anchor为窗口, 看其窗口是否存在物体, 如果有物体, 预测其类别以及位置. 无物体则预测为背景.（SSD的训练目标是预测与anchor重合的图像到底是什么物体）
![这里随便写文字](https://pic2.zhimg.com/80/v2-4986e475ba65f670a0d2ff5f253ddaf5_hd.jpg)

2.2.4 类不平衡问题

这样就引出了一个问题, 一张图, 相当于我们一次训练8732张图片, 但这8732张图片大部分是背景图, 这样就产生了严重的类不平衡问题, 如下图. SSD解决的方法就是通过启发式采样, 每次并不训练8732张图片, 而是训练所有的正样本, 然后再取loss最大的负样本k个, 使得正负样本比例为1:3. 虽然这一定程度上缓解了类不平衡问题, 但实际上, 由于训练的的负样本总数是不变的, 每次训练, 每个负样本依旧都有机会与正样本进行训练, 导致负样本在训练时, 对loss的贡献要覆盖了正样本对loss的贡献, 影响了梯度更新的正确方向, 导致模型无法学习到有用的特征.
![这里随便写文字](https://pic4.zhimg.com/80/v2-d46e0071e7c7b139371314b3f6bdace3_hd.jpg)



## 三、实验结果

&emsp;&emsp;数据增强十分重要。在Faster R-CNN中只使用了水平翻转，而SSD中使用了更为强大的采样策略，类似于YOLO，使最终的mAP提升了接近9%。数据增强对于小物体效果显著；

![这里随便写文字](https://github.com/clw5180/CV_Paper/raw/master/res/SSD/5.png)

## 四、结论
SSD这类1-stage的检测模型实际上是把一张完整的图分成固定大小与长宽比的成千上万个划窗, 分别预测类别与bounding box。
理解一个模型, 不仅仅要理解网络结构, 还需要理解训练过程的数据流, 才能知道模型到底学习了什么. 例如, SSD的训练过程, 实际上可以看成多张图片进行分类与回归, 因此会出现类不平衡问题。
SSD预测的目标就是以一张图中所有anchor为窗口, 看其窗口是否存在物体, 如果有物体, 预测其类别以及位置. 无物体则预测为背景. 醍醐灌顶~ 非常感谢
