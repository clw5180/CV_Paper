

# **Feature Pyramid Networks for Object Detection**

论文地址：<https://arxiv.org/abs/1612.03144v2>



## 一、介绍

&emsp;&emsp;在Faster RCNN中，**RPN网络作用在高层的feature map（conv5_3），利用的是VGG-16的最后的卷积特征，大小是7x7x512**，而这种做法造成了一个问题，经过多次卷积之后的特征通常拥有很大的感受野，**比较适合用来检测大物体，但缺陷是对小物体不友好**（因为对于小目标来说，当进行卷积池化到最后一层，**实际上语义信息已经没有了，因为我们都知道对于一个RoI映射到某个feature  map的方法就是将底层坐标直接除以stride，显然越到后面，映射过去后就越小，甚至可能就没有了**）。为了处理小物体，经典的方式是采用图像金字塔的方式在训练或测试阶段对图片进行多尺度变化增强，但是这样带来了极大的计算量。本文方法通过构造一种独特的特征金字塔来避免图像金字塔的计算量过高的问题，同时能较好的处理物体检测中的多尺度变化问题。

&emsp;&emsp;特征金字塔是处理多尺度物体检测问题的一个基础组成部分。然而，最近基于深度学习的物体检测算法考虑到计算量和内存限制都尽量避免采用特征金字塔的方式。在这篇文章中，作者探索一种**利用深度卷积网络本身固有的多尺度、层次结构来构造特征金字塔，它的好处是只会带来极小的额外消耗**。具体的，本文构造了一种自顶向下、带有侧向连接的层次结构来构建各个尺度的高层语义特征。这种方法称之为Feature Pyramid Network (FPN)。FPN可以作为一种通用的特征提取器，并且在多个任务上带来了显著的性能提升。将FPN应用于Faster RCNN，在COCO上达到了最佳的单模型性能。另外，FPN的推理速度在GPU上可以达到 5FPS，因此是一种检测性能高，同时推理速度能达到实际使用的方法。

![这里随便写文字](https://github.com/clw5180/CV_Paper/raw/master/res/FPN/1.png)

&emsp;&emsp;如何**处理大范围尺度变化**的物体是计算机视觉中的一个基本问题。图像特征金字塔（图a ）在传统的基于手动设计特征的方法中非常常用。一个极端的例子是DPM方法使用了接近10种不同尺度来取得不错的效果。近年来，深度卷积网络的提出几乎完全替代了传统的基于手动设计特征的方法。深度神经网络本身对输入的图像具有较强的尺度鲁棒性（图b ），因此被广泛应用于各种物体检测系统。然而，最近的ImageNet和COCO物体检测比赛结果表明，通过采用测试时多尺度的图像金字塔仍然可以提升最终的性能。这说明当前基于单层特征的检测系统还是具有一定的局限性。虽然特征金字塔网络对传统方法和CNN方法都有一定程度的帮助，它有一个重大的缺陷无法忽视：带来了极大的计算量和内存需求。因此，**现在的检测算法（例如Fast/Faster RCNN）一般在训练时采用单尺度的方式来加速训练，同时测试时用多尺度的方式来提升最终的性能**。除了图像金字塔可以用来处理多尺度的物体，深度网络本身具有的多层次结构也可以用来提取多尺度的特征（图c）。例如SSD方法[6]中就利用了多个特征层分别做预测。然而，由于底层的语义特征比较弱，在处理小物体（特征一般只出现在较低的特征层）时效果表现得不够好。本文提出一种合理利用深度卷积网络各个层次特征的方法（图d），它能较好的让各个不同尺度的特征都具有较强的语义信息。该方法称为Feature Pyramid Network (FPN)，它能应用于物体识别、语义分割等任务中。FPN结合Faster RCNN可以在COCO物体检测比赛中取得当前单模型的最佳性能（SOTA）。另外，通过对比实验发现，FPN能使Faster RCNN中的RPN网络的召回率提高8个点；不仅如此，它也能**使Fast RCNN的检测性能提升2.3个点（COCO）和3.8个点（VOC）**。



## 二、主要内容

- #### FPN算法

FPN的目标是利用卷积网络本身带有的层次性语义特征，来构建特征金字塔。这篇文章以Faster RCNN为例，来说明FPN如何应用到RPN和Fast RCNN中。FPN包含两个部分：第一部分是自底向上的过程，第二部分是自顶向下和侧向连接的融合过程。

**自底向上的过程**：自底向上的过程和普通的CNN没有区别。现代的CNN网络一般都是按照特征图大小划分为不同的stage，每个stage之间特征图的尺度比例相差为2。在FPN中，每个stage对应了一个特征金字塔的级别（level），并且每个stage的最后一层特征被选为对应FPN中相应级别的特征。以ResNet为例，**选取conv2、conv3、conv4、conv5层的最后一个残差block层特征作为FPN的特征，记为{C2、C3、C4、C5}**。这几个特征层相对于原图的**步长stride分别为4、8、16、32**。

**自顶向下过程以及侧向连接**：自顶向下的过程通过**上采样**（up-sampling）的方式将顶层的小特征图（例如20）放大到上一个stage的特征图一样的大小（例如40）。**这样的好处是既利用了顶层较强的语义特征（利于分类），又利用了底层的高分辨率信息（利于定位）！**上采样的方法可以用最近邻差值实现。为了将高层语义特征和底层的精确定位能力结合，作者提出类似于残差网络的侧向连接结构。**侧向连接将上一层经过上采样后和当前层分辨率一致的特征，通过相加的方法进行融合**。（这里为了修正通道数量，将当前层先经过1x1卷积操作。）如图所示。
![这里随便写文字](https://github.com/clw5180/CV_Paper/raw/master/res/FPN/2.png)

基于这个思想，fpn从ResNet 34层模型构造了一组新的特征P2~P5，每个特征都是ResNet中不同卷积层融合的结果，具体如下图所示：C5层先经过1x1卷积，得到M5特征。M5通过上采样，再加上C4经过1x1卷积后的特征，得到M4。这个过程再做两次，分别得到M3和M2。M层特征再经过3x3卷积，得到最终的P2、P3、P4、P5层特征。另外，和传统的图像金字塔方式一样，所有P层的通道数都是256。细节图如下所示（以ResNet为例）：
![这里随便写文字](https://github.com/clw5180/CV_Paper/raw/master/res/FPN/3.png)

论文中使用**resnet34层模型**的 conv2到conv5，C2~C5的大小和维度分别是56x56x64，28x28x128，14x14x256，7x7x512，输入图片的size是224x224。所以**在top-down中，先用了一个1x1x256的卷积将C5：7x7x512 变成了M5：7x7x256**， 每一个m之后都接了一个**3x3x256卷积用来消除不同层之间的混叠效果**，其实也就是缓冲作用。关于**P4**的构造，我们**先将m5的feature map加倍**，用简单的**nearest neighbour upsamping**方法就行，这样M5就变成了M5’：14x14x256，**同时C4：14x14x256经过1x1x256得到C4’：14x14x256, 将M5’ + C4’， element-wisely，就可以得到m4:14x14x256**。所以最后的P2~P5大小分别是56x56x256，28x28x256，14x14x256，7x7x256。代码如下：
```
# Build the shared convolutional layers.
# Bottom-up Layers
# Returns a list of the last layers of each stage, 5 in total.
# 扔掉了C1
_, C2, C3, C4, C5 = resnet_graph(input_image, "resnet101", stage5=True)
# Top-down Layers
# TODO: add assert to varify feature map sizes match what's in config
P5 = KL.Conv2D(256, (1, 1), name='fpn_c5p5')(C5)
P4 = KL.Add(name="fpn_p4add")([
    KL.UpSampling2D(size=(2, 2), name="fpn_p5upsampled")(P5),
    KL.Conv2D(256, (1, 1), name='fpn_c4p4')(C4)])
P3 = KL.Add(name="fpn_p3add")([
    KL.UpSampling2D(size=(2, 2), name="fpn_p4upsampled")(P4),
    KL.Conv2D(256, (1, 1), name='fpn_c3p3')(C3)])
P2 = KL.Add(name="fpn_p2add")([
    KL.UpSampling2D(size=(2, 2), name="fpn_p3upsampled")(P3),
    KL.Conv2D(256, (1, 1), name='fpn_c2p2')(C2)])
# Attach 3x3 conv to all P layers to get the final feature maps.
P2 = KL.Conv2D(256, (3, 3), padding="SAME", name="fpn_p2")(P2)
P3 = KL.Conv2D(256, (3, 3), padding="SAME", name="fpn_p3")(P3)
P4 = KL.Conv2D(256, (3, 3), padding="SAME", name="fpn_p4")(P4)
P5 = KL.Conv2D(256, (3, 3), padding="SAME", name="fpn_p5")(P5)
# P6 is used for the 5th anchor scale in RPN. Generated by
# subsampling from P5 with stride of 2.
P6 = KL.MaxPooling2D(pool_size=(1, 1), strides=2, name="fpn_p6")(P5)
# Note that P6 is used in RPN, but not in the classifier heads.
rpn_feature_maps = [P2, P3, P4, P5, P6]
mrcnn_feature_maps = [P2, P3, P4, P5]
# 原文链接：https://blog.csdn.net/u013010889/article/details/78658135/
```

FPN本身不是检测算法，只是一个特征提取器。它需要和其他检测算法结合才能使用。下面介绍FPN如何应用于区域选择网络（RPN）和物体检测网络（Fast RCNN）。



- ####  FPN应用于RPN

之前Faster RCNN中的RPN是通过最后一层的特征（如VGG16的conv5_3）来做的。最后一层的特征经过3x3卷积，得到256个channel的卷积层，再分别经过两个1x1卷积得到类别得分和边框回归结果。**这里将特征层之后的RPN子网络称之为网络头部（network head）**。对于特征层上的每一个点，作者用anchor的方式预设了9个框。这些框本身包含不同的尺度（scale）和不同的长宽比例（ratio）。

**FPN针对RPN的改进是将网络头部应用到每一个P层**。由于每个P层相对于原始图片具有不同的尺度信息，因此作者将原始RPN中的尺度信息分离，让每个P层只处理单一的尺度信息。具体的，**对{32^2、64^2、128^2、256^2、512^2}这五种尺度的anchor，分别对应到{P2、P3、P4、P5、P6}这五个特征层上（注意，这里的base size比如32，是指的在原图中的anchor基准大小，而不是feature map中的）**。每个特征层都处理1:1、1:2、2:1三种长宽比例的候选框。**P6是专门为了RPN网络而设计的，用来处理512大小的候选框。它由P5经过下采样得到**，注意p6是根据论文中所指添加：

![这里随便写文字](https://github.com/clw5180/CV_Paper/raw/master/res/FPN/3_00.png)

**正负样本的界定和Faster RCNN差不多**：如果某个anchor和一个给定的ground truth有最高的IOU或者和任意一个Ground truth的IOU都大于0.7，则是正样本。如果一个anchor和任意一个ground truth的IOU都小于0.3，则为负样本。

改进后的RPN结构如下图所示（参考 https://blog.csdn.net/xiamentingtao/article/details/78598027 ）。

![这里随便写文字](https://github.com/clw5180/CV_Paper/raw/master/res/FPN/3_0.png)

另外，**上述5个网络头部的参数是共享的，这也是强调为什么各阶层输出的channel必须一致的原因，这样才能使用相同的参数，达到共享的目的**。**作者通过实验发现，网络头部参数共享和不共享两种设置得到的结果几乎没有差别。这说明不同层级之间的特征有相似的语义层次**。这和特征金字塔网络的原理一致。



- ####  FPN应用于Fast RCNN

Fast R-CNN 中很重要的是RoI Pooling层，需要对不同层级的金字塔制定不同尺度的RoI。
RoI Pooling层使用region proposal的结果和中间的某一特征图作为输入，得到的结果经过分解后分别用于分类结果和边框回归。 作者将FPN的各个特征层类比为图像金字塔的各个level的特征，从而将不同尺度的RoI映射到对应的特征层上，大尺度RoI就用后面一些的金字塔层，比如P5；小尺度RoI就用前面一点的特征层，比如P4。以224大小的图片输入为例，宽高为w和h的RoI将被映射到的特征级别为k，它的计算公式如下：

![这里随便写文字](https://github.com/clw5180/CV_Paper/raw/master/res/FPN/4.png)

224是ImageNet的标准输入，k0是基准值，设置为5，代表P5层的输出（原图大小就用P5层），w和h是RoI区域的长和宽，假设RoI是112 * 112的大小，那么k = k0-1 = 5-1 = 4，意味着该RoI应该使用P4的特征层。k值应该会做取整处理，防止结果不是整数。
然后，因为作者把conv5也作为了金字塔结构的一部分，那么从前全连接层的那个作用怎么办呢？这里采取的方法是增加两个1024维的轻量级全连接层，然后再跟上分类器和边框回归，认为这样还能使速度更快一些。





- #### FPN应用于Faster RCNN

主要做以下2点改进：

**首先，Faster-RCNN中原有的VGG网络换成ResNet-101**，ResNet-101结构如下图：

![这里随便写文字](https://github.com/clw5180/CV_Paper/raw/master/res/FPN/5.jpeg)

**其次，Faster-RCNN利用conv1到conv4_x的91层为共享卷积层，然后从conv4_x的输出开始分叉**，一路经过RPN网络进行区域选择，把RPN的结果输入RoI Pooling层；另一路直接连一个RoI Pooling层，经过RoI Pooling后映射到7x7（自注：还是14x14？）大小的特征。然后将经过RoI Pooling后的特征再进入原来的conv5_x的计算，进而得到最终的分类和边框回归结果。**这里conv5_x起到原来全连接层（fc）的作用**。在FPN中，conv5层已经被用来作为特征提取器得到P5层；因此，这里单独设计两个1024维的全连接层作为检测网络的网络头部。新的网络头部是随机初始化的，它相比于原来的conv5层更加轻量级。整体框架用下图表示：

![这里随便写文字](https://github.com/clw5180/CV_Paper/raw/master/res/FPN/6.png)



## 三、实验结果

&emsp;&emsp;



## 四、结论

* 作者提出的FPN（Feature Pyramid Network）算法同时利用**低层特征高分辨率和高层特征的高语义信息**，通过融合这些不同层的特征达到预测的效果。并且**预测是在每个融合后的特征层上单独进行的**，这和常规的特征融合方式不同。

